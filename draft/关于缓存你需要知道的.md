# About Cache

作后端开发的同学，必须要掌握缓存技术的使用。这是你不需要花费太多的精力就能显著提升服务性能的灵丹妙药。前提是你得知道如何使用它，这样才能够最大限度发挥它的功效，并抑制其副作用。本文将介绍最基本的缓存使用方法：怎么加缓存，怎么更新它。

## 开始之前

这部分将介绍在开始加缓存之前我们必须要做的事情。这步非常重要，如果没弄好，很有可能加了缓存反而不如不加。

为什么要用缓存？对于一个服务其性能瓶颈往往都在DB，传统关系型存储尤甚。我们在创建表的时候，并不会未所有的字段创建索引，这意味着如果我们需要读取非缓存数据就要从磁盘拿数据。这个过程至少需要十几毫秒的时间。而缓存往往是基于内存的，这要比DB读数据快两个数量级。这是我们用缓存的根本原因原因。

那干脆把所有的数据扔到内存不就行了嘛！不行。内存这东西虽然很快，同时它还很贵。动辄百十来G的数据都扔内存这有点太浪费。依据二八定律，我们只需找到那最紧俏的百分之二十就行了。这是非常重要的。否则你加了缓存效果反而更差。

对于缓存有一个衡量指标，叫做缓存命中率。这个指标高说明我们请求的数据大部分来自缓存。证明我们加缓存这件事的收益越高。

## 加缓存

如果你平时都用一些ORM工具很可能下边这些问题你不会直接遇到，不过这些问题都是在你加缓存之前需要着实想清楚的。算是一些通用的套路。我们逐条来看一下：

### 缓存穿透

缓存穿透是说访问一个缓存中没有的数据，但是这个数据数据库中也不存在。普通思路下我们没有从数据库中拿到数据是不会触发加缓存操作的。这时如果是有人恶意攻击，大量的访问就会透过缓存直接打到数据库，对后端服务和数据库做成巨大的压力甚至宕机。

解决方案：

- 缓存空对象。这个缓存对象需要设置一个较短的过期时间，时期尽快的被回收。

- 布隆过滤器。//TODO

### 缓存并发

缓存并发这个场景很容易解释：多个客户端同时访问一个没有在cache中的数据，就会造成缓存并发。

解决方案：

- 预先预热数据。把所有预期的热数据加到缓存，定位热数据还是比较复杂的事情，需要根据自己的服务访问情况去评估。

- 缓存加锁。 如果多个客户端访问不存在的缓存时，在执行数据库查询并set缓存这个逻辑之前先加锁，只能让一个客户端执行这段逻辑。

### 缓存防雪崩

缓存雪崩是缓存服务不能提供服务，导致所有的请求都直接访问DB。

解决方案：

- 构建高可用的缓存系统。目前常用的缓存系统Redis和Memcache都支持高可用的部署方式。

- 系统的限流。//TODO

## 更新缓存

这部分我们将介绍一下cache的更新策略。

### Cache Aside Pattern

这种思路先更新数据库，更新成功之后再令缓存失效。还有一种方式是先失效缓存，然后在更新数据库。我们来对比一下这两种方式的不同。

首先，来看后一种。设想一种情景，一个客户端发起更新操作，当执行了缓存失效。这时一个读取操作进来，发现缓存没有数据然后从数据库拿数据并放到缓存。更新操作继续更新数据库。这时缓存里已经缓存了脏数据。

那么第一种会出现这种问题吗？理论上是会的，但是需要具备以下前提：1. 缓存自动失效；2. 更新操作发起，读操作进来时缓存恰好失效，然后从数据库load数据，并set缓存，更新操作执行。只有具备上述两个条件才会出现脏数据，但是这概率已经非常小了。

![cache aside pattern](../images/cache-aside-pattern.png)

- Read/Write Throngh。这个模式是cache代理了数据的全部操作。业务代码里边操作一个cache db。

Read Through。Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。
Write Through。Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库（这一步是为了数据一致性），然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

![read-write-thrugh](../images/read-write-through.png)

- Write Back模式。更新是只更新缓存，然后缓存组建异步的把数据同步到DB中。Is-dirty判断是否从cache 写入到了持久层。

![write-back](../images/write-back.png)
